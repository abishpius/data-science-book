import{_ as i,c as a,o as t,ae as n}from"./chunks/framework.CDjunVez.js";const E=JSON.parse('{"title":"Chapter 4: Data Cleaning and Preparation","description":"","frontmatter":{},"headers":[],"relativePath":"chapters/chapter-4.md","filePath":"chapters/chapter-4.md"}'),e={name:"chapters/chapter-4.md"};function l(h,s,p,o,k,r){return t(),a("div",null,[...s[0]||(s[0]=[n(`<h1 id="chapter-4-data-cleaning-and-preparation" tabindex="-1">Chapter 4: Data Cleaning and Preparation <a class="header-anchor" href="#chapter-4-data-cleaning-and-preparation" aria-label="Permalink to &quot;Chapter 4: Data Cleaning and Preparation&quot;">​</a></h1><p>Handling Missing Data: Imputation vs. Deletion Strategies Data in the real world is rarely pristine. In our previous sections, we ingested CSVs and performed aggregations assuming that every row contained perfect, complete information. We assumed every customer had an age, every transaction had a dollar amount, and every product had a category. In reality, you will encounter datasets that look like Swiss cheese. A survey respondent skipped a question; a sensor went offline for an hour; a legacy database export corrupted a specific text field. In Excel, a blank cell is visually obvious. You might manually scan the sheet, filter for &quot;Blanks,&quot; or use an IF(ISBLANK(), ...) formula. In Pandas, missing data is represented as NaN (Not a Number) or None. If you attempt to calculate the sum or average of a column containing NaN values without handling them, your analysis may either crash or, worse, silently produce skewed results. This section focuses on the two primary strategies for handling these gaps: Deletion (removing the data) and Imputation (guessing the data). Identifying the Gaps Before you fix the problem, you must quantify it. You cannot simply &quot;look&quot; at a DataFrame with 50,000 rows to find blank cells. Let&#39;s imagine a DataFrame named crm_data containing customer leads.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pandas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Sample data with intentional gaps</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Company&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Acme Corp&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Globex&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Soylent Corp&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Initech&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Umbrella Corp&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Revenue&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, np.nan, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">500000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">75000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, np.nan],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Employee_Count&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">50</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1200</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, np.nan, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">500</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Sector&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Tech&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Logistics&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Food&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Tech&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, np.nan]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">crm_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd.DataFrame(data)</span></span></code></pre></div><p>If you print this DataFrame, you will see NaN where data is missing. To get a high-level summary of your &quot;data hygiene,&quot; use the .info() method or chain .isnull().sum().</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Check for missing values per column</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(crm_data.isnull().sum())</span></span></code></pre></div><p><strong>Output:</strong></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span></span></span>
<span class="line"><span>\`\`\`text</span></span>
<span class="line"><span>Company           0</span></span>
<span class="line"><span>Revenue           2</span></span>
<span class="line"><span>Employee_Count    1</span></span>
<span class="line"><span>Sector            1</span></span>
<span class="line"><span>dtype: int64</span></span>
<span class="line"><span> A visual representation of a DataFrame heatmap using the &#39;seaborn&#39; library. The heatmap shows yellow bars representing valid data and black gaps representing missing (NaN) values, illustrating how data gaps can be distributed randomly across rows and columns.</span></span></code></pre></div><p>A visual representation of a DataFrame heatmap using the &#39;seaborn&#39; library. The heatmap shows yellow bars representing valid data and black gaps representing missing (NaN) values, illustrating how data gaps can be distributed randomly across rows and columns. Once you know where the holes are, you have to make a business decision: do you cut the rot out, or do you try to repair it? Strategy 1: Deletion (The &quot;Nuclear&quot; Option) Deletion is the simplest approach. If a row is incomplete, you remove it. In statistical terms, this is &quot;Listwise Deletion.&quot; In Pandas, we use the .dropna() method. Dropping Rows If you are analyzing &quot;Revenue per Company,&quot; a row with no Revenue data is useless to you.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Drop any row that contains at least one missing value</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">clean_rows </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crm_data.dropna()</span></span></code></pre></div><p>However, be careful. If you have a dataset with 10 columns, and a row is missing data in only one unimportant column (e.g., &quot;Fax Number&quot;), dropna() will delete the entire customer record. You might lose valuable data in the &quot;Revenue&quot; column just because the &quot;Fax Number&quot; was missing. To refine this, you can use the subset parameter:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Only drop rows where &#39;Revenue&#39; is missing. </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Keep the row even if &#39;Sector&#39; is missing.</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">valid_revenue_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crm_data.dropna(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">subset</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Revenue&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span></code></pre></div><p>Dropping Columns Sometimes, the problem isn&#39;t the observation (row); it&#39;s the feature (column). If you ingest a dataset where the &quot;Second Phone Number&quot; column is 95% blank, imputing it is impossible, and deleting the rows would leave you with no data. The solution is to drop the column entirely.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Drop columns (axis=1) that have any missing values</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Note: In practice, you usually drop specific columns by name using .drop()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">crm_data_trimmed </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crm_data.dropna(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>The Trade-off: Deletion ensures that the data you do analyze is real and observed. However, it reduces your sample size (statistical power) and can introduce bias if the data is not &quot;missing at random&quot; (e.g., if only unhappy customers skip the &quot;Satisfaction Score&quot; question, deleting those rows makes your customers look happier than they are). Strategy 2: Imputation (Filling in the Blanks) Imputation involves replacing missing data with a substitute value based on other available information. In Pandas, we use the .fillna() method. Constant Imputation This is common for categorical data or specific business logic. If a customer has no &quot;Assigned Sales Rep,&quot; you might fill that blank with &quot;Unassigned.&quot; If a &quot;Discount Code&quot; field is empty, you might assume the discount is 0.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Fill missing Sector values with &#39;Unknown&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">crm_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sector&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crm_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sector&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].fillna(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Unknown&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Fill missing Revenue with 0 (Use with caution!)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">crm_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Revenue&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crm_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Revenue&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].fillna(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A flowchart decision tree. The top box asks </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Is the missing value numerical or categorical?&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">. The Categorical path leads to </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Fill with &#39;Unknown&#39; or Mode&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">. The Numerical path splits into </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Time Series&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (Forward Fill) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;General&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (Mean</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Median Imputation).</span></span></code></pre></div><p>A flowchart decision tree. The top box asks &quot;Is the missing value numerical or categorical?&quot;. The Categorical path leads to &quot;Fill with &#39;Unknown&#39; or Mode&quot;. The Numerical path splits into &quot;Time Series&quot; (Forward Fill) and &quot;General&quot; (Mean/Median Imputation). Statistical Imputation (Mean vs. Median) For numerical data, filling with 0 is often dangerous. If you are analyzing the average height of adults, filling missing values with 0 will drastically drag down your average. Instead, we usually fill the gap with the Mean (average) or Median (middle value) of that column.</p><ul><li>Mean Imputation: Best for normally distributed data (bell curve).</li><li>Median Imputation: Best for data with outliers (skewed data). Consider our Employee_Count. If most companies have 50 employees, but one has 50,000, the average will be artificially high. The median is safer for things like salaries, house prices, or company sizes.</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Calculate the median of existing values</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">median_employees </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crm_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Employee_Count&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].median()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Fill the missing values with that calculated median</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">crm_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Employee_Count&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> crm_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Employee_Count&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].fillna(median_employees)</span></span></code></pre></div><p>Context-Aware Imputation (Grouping) This is the &quot;Pro&quot; move. In Excel, you might fill a missing value with the overall average. In Python, you can be more specific. Imagine a missing &quot;Salary&quot; field. Instead of filling it with the average salary of everyone, you can fill it with the average salary of people with the same Job Title.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Concept example: Fill missing salary with the average salary of that specific job title</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Salary&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.groupby(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Job_Title&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Salary&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].transform(</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: x.fillna(x.mean())</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>This creates a much more accurate guess than a blanket average. Special Case: Time Series Data If you are analyzing stock prices or daily temperature, the &quot;average&quot; is not a good guess for a missing day. If you are missing data for Tuesday, the best guess is usually whatever happened on Monday. This is called Forward Fill (ffill).</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># If data is missing, take the value from the previous row</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">stock_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Price&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> stock_data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Price&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].fillna(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">method</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;ffill&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Summary: Which Strategy to Use? | Scenario | Strategy | Pandas Method | | :--- | :--- | :--- | | Rows with crucial missing data | Deletion | df.dropna(subset=[&#39;Column&#39;]) | | Columns with &gt; 50% missing data | Deletion | df.drop(columns=[&#39;Column&#39;]) | | Categorical data (e.g., Region) | Constant Imputation | df.fillna(&#39;Unknown&#39;) | | Numerical data (Normal distribution) | Mean Imputation | df.fillna(df.mean()) | | Numerical data (With outliers) | Median Imputation | df.fillna(df.median()) | | Time Series / Sequential data | Forward Fill | df.fillna(method=&#39;ffill&#39;) | Handling missing data is more art than science. It requires understanding why the data is missing. Always document your decision. If you choose to fill missing revenue with the median, state that clearly in your final report, as it fundamentally changes the nature of the dataset. Data Type Conversion and Formatting Consistency In Excel, data types are often a suggestion rather than a rule. You can type a date into cell A1, a currency figure into A2, and a text comment into A3, and Excel won’t complain. It applies formatting dynamically, often guessing what you intend. If you type &quot;100&quot; and &quot;200&quot; as text, Excel might still helpfully sum them up to &quot;300&quot; if you use a formula. In Python, however, types are strict. A common frustration for professionals moving to Data Science occurs during their first aggregation attempt. You load a sales dataset, group by region, and try to sum the Revenue column. Instead of a dollar amount, you get an error, or worse, a concatenation of strings like 10002000500. This happens because Pandas is treating your numbers as text. This section covers how to audit, force, and fix data types to ensure your analysis rests on a solid mathematical foundation. The &quot;Object&quot; Trap When Pandas loads a CSV file, it scans the data to determine what type belongs in each column. If a column contains integers, it assigns an int64 type. If it sees decimals, it assigns float64. However, if a column contains a mix of numbers and strings—or if your numbers contain non-numeric characters like currency symbols ($), commas (,), or percentage signs (%)—Pandas defaults to the safest, most flexible type available: object. In the Pandas world, object is synonymous with &quot;string&quot; or &quot;mixed data.&quot; A visual comparison between two columns. Left Column: &quot;Excel Style&quot; showing mixed content (numbers with dollar signs, text). Right Column: &quot;Pandas Style&quot; showing the underlying data type storage. The Excel column looks nice but is messy; the Pandas column is labeled &#39;Dtype: Object&#39; and highlights that mathematical operations are blocked.</p><p>A visual comparison between two columns. Left Column: &quot;Excel Style&quot; showing mixed content (numbers with dollar signs, text). Right Column: &quot;Pandas Style&quot; showing the underlying data type storage. The Excel column looks nice but is messy; the Pandas column is labeled &#39;Dtype: Object&#39; and highlights that mathematical operations are blocked. Before doing any analysis, you must check your types using the .info() or .dtypes attribute.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pandas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># A sample dataset representing common &quot;dirty&quot; business data</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Customer_ID&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">101</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">102</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">103</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">104</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Join_Date&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;2023-01-15&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;2023/02/10&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Mar 1, 2023&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;2023-04-20&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Sales_Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;$1,000.00&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;$2,500.50&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Pending&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;$450.00&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Department&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sales &#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;sales&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Marketing&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39; Sales&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd.DataFrame(data)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df.dtypes)</span></span></code></pre></div><p><strong>Output:</strong></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span></span></span>
<span class="line"><span>\`\`\`text</span></span>
<span class="line"><span>Customer_ID      int64</span></span>
<span class="line"><span>Join_Date       object</span></span>
<span class="line"><span>Sales_Amount    object</span></span>
<span class="line"><span>Department      object</span></span>
<span class="line"><span>dtype: object</span></span></code></pre></div><p>Notice that Sales_Amount is an object. You cannot sum this column yet. Converting Numbers: Stripping and Forcing To convert Sales_Amount to a number, you cannot simply command Python to &quot;make it a number.&quot; Python doesn&#39;t know what to do with the $ or the ,. You must first clean the strings, then convert the type. We use the .astype() method for clean conversions and pd.to_numeric() for messier situations. Step 1: String Manipulation We access string methods in Pandas using the .str accessor. Here, we replace symbols with nothing (empty strings).</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Remove &#39;$&#39; and &#39;,&#39; from the column</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sales_Amount_Clean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sales_Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.replace(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;$&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">regex</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).str.replace(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;,&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">regex</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Step 2: Handling Non-Numeric Values Even after removing symbols, our dataset contains the word &quot;Pending&quot;. If we try to convert &quot;Pending&quot; to a number, Python will crash. We use pd.to_numeric with the errors=&#39;coerce&#39; argument. This argument tells Pandas: &quot;If you find something that isn&#39;t a number, don&#39;t crash; just turn it into NaN (Not a Number).&quot; A flowchart illustrating the &#39;pd.to_numeric&#39; logic. Input: A list [&quot;100&quot;, &quot;200&quot;, &quot;Pending&quot;]. Processing: &#39;errors=coerce&#39; acts as a filter. Output: The list becomes [100.0, 200.0, NaN], with &quot;Pending&quot; dropping into a waste bin labeled &#39;Missing Data&#39;.</p><p>A flowchart illustrating the &#39;pd.to_numeric&#39; logic. Input: A list [&quot;100&quot;, &quot;200&quot;, &quot;Pending&quot;]. Processing: &#39;errors=coerce&#39; acts as a filter. Output: The list becomes [100.0, 200.0, NaN], with &quot;Pending&quot; dropping into a waste bin labeled &#39;Missing Data&#39;.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Convert to numeric, turning &quot;Pending&quot; into NaN</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sales_Amount_Clean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd.to_numeric(df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sales_Amount_Clean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">errors</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;coerce&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df[[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sales_Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Sales_Amount_Clean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df.dtypes)</span></span></code></pre></div><p>Now, Sales_Amount_Clean is a float64. You can calculate the mean, sum, or standard deviation. The Datetime Standard In Excel, dates are actually serial numbers formatted to look like dates. In Pandas, we convert date-like strings into Timestamp objects. This allows us to easily extract the year, month, or day, and perform time-series logic (e.g., &quot;subtract 30 days from today&quot;). In our sample data, Join_Date has mixed formats (2023-01-15 vs Mar 1, 2023). Pandas is surprisingly intelligent at parsing these using pd.to_datetime.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Convert the Join_Date column to datetime objects</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Join_Date&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd.to_datetime(df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Join_Date&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Now we can extract features easily</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Month&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Join_Date&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].dt.month_name()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df[[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Join_Date&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Month&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]])</span></span></code></pre></div><p>Note: If your dates are in a very specific non-standard format (like <code>15012023</code> for Jan 15, 2023), you may need to provide a format string, similar to Excel custom formatting, using the <code>format</code> argument. String Consistency: The Silent Grouping Killer One of the most insidious issues in data cleaning is string inconsistency. To a human, &quot;Sales&quot;, &quot;sales&quot;, and &quot; Sales &quot; (with a leading space) are the same department. To a computer, they are three distinct categories. If you run a groupby on the Department column in our sample data without cleaning it, you will get three separate rows for Sales. A diagram showing a GroupBy operation failing due to string inconsistencies. Three buckets labeled &quot;Sales&quot;, &quot;sales&quot;, and &quot; Sales &quot; collect data separately. An arrow points to a &quot;Unified Bucket&quot; labeled &quot;sales&quot; showing how cleaning merges them.</p><p>A diagram showing a GroupBy operation failing due to string inconsistencies. Three buckets labeled &quot;Sales&quot;, &quot;sales&quot;, and &quot; Sales &quot; collect data separately. An arrow points to a &quot;Unified Bucket&quot; labeled &quot;sales&quot; showing how cleaning merges them. To fix this, we standardize casing and remove whitespace.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 1. Make everything lowercase</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 2. Strip whitespace from the start and end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Department&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Department&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.lower().str.strip()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Now verify the unique values</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Department&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].value_counts())</span></span></code></pre></div><p><strong>Output:</strong></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span></span></span>
<span class="line"><span>\`\`\`text</span></span>
<span class="line"><span>sales        3</span></span>
<span class="line"><span>marketing    1</span></span></code></pre></div><p>Name: Department, dtype: int64 By chaining .str.lower() and .str.strip(), we have collapsed three fragmented categories into a single, authoritative &quot;sales&quot; group. Summary of Type Conversion As you prepare your data for analysis, your checklist for consistency should look like this:</p><ol><li>Check <code>dtypes</code> immediately: Don&#39;t assume numbers are numbers. 2. Clean then Convert: Remove currency symbols and commas before converting to numeric. 3. Coerce Errors: Use pd.to_numeric(..., errors=&#39;coerce&#39;) to handle messy data points without stopping your script. 4. Standardize Strings: Always strip whitespace and unify capitalization on categorical text columns before aggregating. With your data types strictly defined and formatted, your DataFrames are no longer just fragile tables—they are structured datasets ready for heavy analysis. String Manipulation: Cleaning Textual Categories and Names In the previous section, we tackled the strict nature of Python data types. We ensured that our sales figures are recognized as floats and our transaction dates are actually timestamps, not strings of text. However, simply having a column typed as object (text) does not mean the data inside it is ready for analysis. In fact, text data is notoriously messy. Human entry introduces typos, capitalization inconsistencies, and invisible whitespace. Consider a scenario where you want to group sales by the &quot;Department&quot; column. In Excel, you might see a Dropdown list containing: <code>Marketing</code> marketing <code>Marketing </code> (note the trailing space) Mktg To a human, these refer to the same department. To a computer (and to Python), these are four completely unique values. If you run a groupby aggregation on this column, you won&#39;t get one total for Marketing; you will get four fragmented totals. In Excel, you would fix this using a combination of TRIM(), PROPER(), and &quot;Find &amp; Replace.&quot; In Pandas, we handle this through the vectorized string accessor: .str. The .str Accessor: Your Text Toolkit When working with a single string in standard Python, you can use methods like &quot;text&quot;.upper(). However, a Pandas Series (a column) is not a string; it is a container of strings. If you try to run df[&#39;Department&#39;].upper(), Python will throw an error because the list itself doesn&#39;t have an upper method. You need to tell Pandas to look inside the container and apply the logic to every row. We do this by accessing the .str library attached to the series. A diagram showing a Pandas Series column on the left with mixed casing and whitespace. An arrow labeled &quot;.str accessor&quot; points to the right, showing the methods .upper(), .strip(), and .split() being applied to each individual cell simultaneously.</li></ol><p>A diagram showing a Pandas Series column on the left with mixed casing and whitespace. An arrow labeled &quot;.str accessor&quot; points to the right, showing the methods .upper(), .strip(), and .split() being applied to each individual cell simultaneously. Standardization: Case and Whitespace The two most common reasons for &quot;duplicate&quot; categories are inconsistent capitalization and invisible whitespace (spaces at the beginning or end of a cell). Let&#39;s look at a sample dataset of client names:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pandas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Client_Name&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Acme Corp&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;acme corp&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Acme Corp &#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Globex&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;GLOBEX &#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Contract_ID&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">101</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">102</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">103</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">104</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">105</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd.read_csv(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;clients.csv&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Assuming we loaded this data</span></span></code></pre></div><p>If we count the unique values here, Python sees five distinct clients. To fix this, we standardize the text. Changing Case Just like Excel&#39;s =UPPER(), =LOWER(), and =PROPER() functions, Pandas offers: <code>.str.lower()</code>: Converts to lowercase. .str.upper(): Converts to uppercase. * .str.title(): Capitalizes the first letter of each word. Removing Whitespace The &quot;invisible enemy&quot; in data science is the trailing space. It often occurs when data is exported from legacy SQL databases that pad text fields to a fixed length. In Excel, you use =TRIM(). In Pandas, you use .str.strip(). Here is how we clean the client names in one sweep:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Step 1: Remove whitespace from both ends</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Client_Name&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Client_Name&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.strip()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Step 2: Convert to title case (e.g., &quot;Acme Corp&quot;)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Client_Name&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Client_Name&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.title()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Result: Only two unique clients remain (&#39;Acme Corp&#39; and &#39;Globex&#39;)</span></span></code></pre></div><p>Replacing Substrings and Cleaning Logic Sometimes standardization isn&#39;t enough. You may need to fix typos, remove specific characters (like currency symbols), or map abbreviations to full names. In Excel, you might use SUBSTITUTE() or the &quot;Find and Replace&quot; dialog box. In Pandas, we use .str.replace(). Imagine a &quot;Revenue&quot; column that was imported as text because it included the &quot;$&quot; sign and commas (e.g., &quot;$1,200.50&quot;). To convert this to a number, we must first remove the non-numeric characters.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Remove &#39;$&#39; and &#39;,&#39; from the string</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Note: regex=False tells Python to treat the search strictly as text, not a pattern</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Revenue_Clean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Revenue&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.replace(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;$&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">regex</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).str.replace(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;,&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">regex</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Now we can convert the type</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Revenue_Clean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Revenue_Clean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].astype(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>You can also use replace to fix categorical inconsistencies, such as changing &quot;Mktg&quot; to &quot;Marketing&quot;:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Department&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Department&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.replace(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Mktg&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Marketing&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Before and After&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> table visualization. The left side shows a dirty dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> symbols, abbreviations, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> inconsistent casing. The right side shows the clean dataset after .str.replace operations, highlighting the specific changes </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a contrasting color.</span></span></code></pre></div><p>A &quot;Before and After&quot; table visualization. The left side shows a dirty dataset with symbols, abbreviations, and inconsistent casing. The right side shows the clean dataset after .str.replace operations, highlighting the specific changes in a contrasting color. Splitting Text: The &quot;Text-to-Columns&quot; Equivalent One of the most beloved features in Excel is the Text-to-Columns wizard, which allows you to split a &quot;Full Name&quot; column into &quot;First Name&quot; and &quot;Last Name&quot; based on a delimiter (like a comma or space). In Pandas, we achieve this with .str.split(). Consider a column Location formatted as &quot;City, State&quot; (e.g., &quot;Austin, TX&quot;).</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># This creates a list inside the cell: [&#39;Austin&#39;, &#39;TX&#39;]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Location&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.split(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;,&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>However, we usually want these in separate columns, not a list. We use the expand=True argument to separate the results into a new DataFrame structure.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Split into two new columns</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;City&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;State&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Location&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.split(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;,&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">expand</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Clean up the whitespace that might be left after the comma in &#39; State&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;State&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;State&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].str.strip()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">String Slicing</span></span></code></pre></div><p>Sometimes you don&#39;t need to split by a delimiter; you need to extract a specific number of characters. In Excel, you use =LEFT(cell, 2) or =RIGHT(cell, 4). In Pandas, because the .str accessor treats the column like a Python string, you can use slicing directly.</p><ul><li>Excel: =LEFT(A1, 3)</li><li>Pandas: df[&#39;col&#39;].str[:3]</li><li>Excel: =RIGHT(A1, 2)</li><li>Pandas: df[&#39;col&#39;].str[-2:] Summary Checklist When preparing textual data for aggregation or analysis, run through this mental checklist:</li></ul><ol><li>Check for Case: Do &quot;Apple&quot; and &quot;apple&quot; exist? Use .str.title() or .str.lower(). 2. Check for Whitespace: Are there phantom spaces? Always run .str.strip(). 3. Check for Artifacts: Are there symbols ($%#) preventing math? Use .str.replace(). 4. Check Structure: Is useful data combined? Use .str.split(expand=True). By mastering the .str accessor, you transform raw, messy text into structured categories, allowing the GroupBy and Pivot Table operations we discussed earlier to function accurately. Detecting and Managing Outliers in Financial and Operational Data In the previous section, we discussed how to standardize text data, ensuring that &quot;New York,&quot; &quot;new york,&quot; and &quot;NY&quot; are treated as the same entity. We cleaned up the labels of our data. Now, we must look at the values themselves—specifically, the values that look suspicious. In business analytics, there is a famous joke: &quot;Bill Gates walks into a bar. Suddenly, on average, everyone in the bar is a billionaire.&quot; This highlights the danger of outliers. In financial and operational data, an outlier is a data point that differs significantly from other observations. Sometimes, these are errors (e.g., a cashier entered $1,000,000 instead of $100). Other times, they are legitimate but extreme events (e.g., a &quot;whale&quot; customer placing a massive order). In Excel, you might spot these by sorting a column from Largest to Smallest and seeing if the top number makes sense. In Python, relying on manual sorting is risky because you can’t eyeball a million rows. Instead, we use statistical rules and visualization to detect these anomalies systematically. The Danger of the Mean Before we write code, understand why we do this. Outliers wreak havoc on standard aggregation metrics, particularly the Mean (Average). If you are analyzing &quot;Time to Ship&quot; for a logistics company, and 99 packages ship in 2 days, but one package gets lost and ships in 200 days, your average shipping time might jump to 4 days. If you report &quot;Average shipping is 4 days&quot; to management, you are misleading them—most customers get their packages in 2 days. A comparison chart showing two distributions. On the left, a normal distribution where the Mean and Median are the same. On the right, a skewed distribution (like income or transaction value) where a few high outliers pull the Mean far to the right, while the Median remains representative of the majority.</li></ol><p>A comparison chart showing two distributions. On the left, a normal distribution where the Mean and Median are the same. On the right, a skewed distribution (like income or transaction value) where a few high outliers pull the Mean far to the right, while the Median remains representative of the majority. Visual Detection: The Boxplot The fastest way to detect outliers in Python is not a table, but a Boxplot. A boxplot (or box-and-whisker plot) provides a visual summary of the central tendency and variability of your data. It draws a box around the middle 50% of your data and extends &quot;whiskers&quot; to the rest. Any dots floating beyond those whiskers are statistically considered outliers. Let&#39;s look at a dataset of invoice amounts:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pandas </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> matplotlib.pyplot </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> plt</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> seaborn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sns</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Sample financial data</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Invoice_ID&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">110</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">105</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">98</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">102</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">95</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">108</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">101</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Note the 5000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pd.DataFrame(data)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Visualizing with a Boxplot</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plt.figure(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">figsize</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">sns.boxplot(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">x</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plt.title(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Distribution of Invoice Amounts&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plt.show()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A boxplot generated </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> the code above. The box </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> squashed on the left side around the </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mark. A single lonely dot sits far to the right at the </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mark. Arrows analyze the plot: identifying the </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Interquartile Range&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (the box) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> the </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Outlier&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (the dot).</span></span></code></pre></div><p>A boxplot generated from the code above. The box is squashed on the left side around the 100 mark. A single lonely dot sits far to the right at the 5000 mark. Arrows analyze the plot: identifying the &quot;Interquartile Range&quot; (the box) and the &quot;Outlier&quot; (the dot). In the resulting plot, the &quot;box&quot; will be squashed near 100, and a single dot will sit far away at 5000. That dot is your anomaly. Statistical Detection: The IQR Method Visuals are great for exploration, but you cannot automate a pipeline based on looking at pictures. You need a mathematical rule to define what counts as an &quot;outlier.&quot; In Data Science, the standard industry method for non-normal data (like prices or salaries) is the Interquartile Range (IQR) Method. Here is the logic, which mimics how the boxplot is constructed: 1. Q1 (25th Percentile): The value below which 25% of the data falls. 2. Q3 (75th Percentile): The value below which 75% of the data falls. 3. IQR: The difference between Q3 and Q1 (the middle 50% of data). 4. The Fence: We calculate &quot;fences&quot; or limits. Any data point outside these fences is an outlier. Lower Limit = $Q1 - (1.5 \\times IQR)$ Upper Limit = $Q3 + (1.5 \\times IQR)$ Let&#39;s apply this logic using Pandas:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Calculate Q1 and Q3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Q1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].quantile(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.25</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Q3 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].quantile(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.75</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Calculate IQR</span></span></code></pre></div><p>IQR = Q3 - Q1</p><h1 id="define-the-bounds" tabindex="-1">Define the bounds <a class="header-anchor" href="#define-the-bounds" aria-label="Permalink to &quot;Define the bounds&quot;">​</a></h1><p>lower_bound = Q1 - 1.5 * IQR upper_bound = Q3 + 1.5 * IQR</p><p>print(f&quot;Normal range is between \${lower_bound:.2f} and \${upper_bound:.2f}&quot;)</p><h1 id="filter-to-find-the-outliers" tabindex="-1">Filter to find the outliers <a class="header-anchor" href="#filter-to-find-the-outliers" aria-label="Permalink to &quot;Filter to find the outliers&quot;">​</a></h1><p>outliers = df[(df[&#39;Amount&#39;] &lt; lower_bound) | (df[&#39;Amount&#39;] &gt; upper_bound)] print(&quot;Detected Outliers:&quot;) print(outliers) If you run this code, Python will mathematically confirm that the $5,000 invoice is an outlier because it falls far above the upper_bound. Managing Outliers: Delete, Keep, or Cap? Once you have identified the outliers using the code above, you face a business decision. Python cannot make this decision for you; it requires domain knowledge.</p><ol><li>Removal (Trimming) If the outlier is clearly an error (e.g., a customer age of 150, or a negative price), you should delete it.</li></ol><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Create a clean DataFrame without outliers</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_clean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df[(df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> lower_bound) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (df[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> upper_bound)]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">. Retention If the outlier </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> real (e.g., a massive </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">B2B</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> deal </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a dataset of </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">B2C</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sales), deleting it means lying about your total revenue. In this case, you might keep it, but analyze it separately. You might create a separate report: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Standard Sales Trends&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (excluding outliers) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">and</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Key Account Activity&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (outliers only).</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">. Capping (Winsorization) This </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a common technique </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> financial modeling. Instead of deleting the data, you </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cap&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> it at a specific threshold. If the upper bound </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;"> $</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">\\</span><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">$130$, and you have a value of $\\$5,000$, you replace the $\\$5,000$ with $\\$130$. This preserves the fact that the transaction was &quot;high&quot; without allowing the extreme magnitude to ruin your averages.</span></span></code></pre></div><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Create a copy to avoid SettingWithCopy warnings</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_capped </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> df.copy()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Cap values greater than upper_bound to the upper_bound value</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">df_capped[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.where(df_capped[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> upper_bound, </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                               upper_bound, </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                               df_capped[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Amount&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(df_capped)</span></span></code></pre></div><p>In this capped dataset, the $$5,000$ entry becomes roughly $$126$ (depending on the exact IQR calculation). Your mean is no longer skewed, but you haven&#39;t lost the record entirely. Summary of Logic 1. Visual Check: Use a Boxplot to see if outliers exist. 2. Math Check: Use the IQR method to identify specific rows. 3. Business Decision: Decide if the data is wrong (delete it) or exceptional (cap it or segment it). [[IMAGE: Decision tree flowchart for handling outliers. Step 1: Is the value impossible? (e.g., Age -5). Yes -&gt; Delete/Impute. No -&gt; Step 2. Step 2: Is it a measurement error? Yes -&gt; Delete/Resample. No -&gt; Step 3. Step 3: Does it skew the model significantly? Yes -&gt; Cap/Transform/Log Scale. No -&gt; Keep as is.]] By mastering outlier detection, you ensure that the insights you deliver to your stakeholders describe the reality of the business, rather than the distortions caused by a few data anomalies.</p>`,70)])])}const g=i(e,[["render",l]]);export{E as __pageData,g as default};
